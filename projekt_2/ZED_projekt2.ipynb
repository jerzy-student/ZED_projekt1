{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Projekt z uczenia maszynowego - Jerzy Jankowski\n",
    "\n",
    "Zadania: Celem drugiego projektu jest stworzenie dwóch klasyfikatorów danych krystalograficznych badanych w ramach analizy w języku R. Pierwszy klasyfikator powinien być nauczony na podstawie oryginalnego zbioru etykiet (res_name), a drugi na podstawie pogrupowanych etykiet (group_label), które dostarczy prowadzący.\n",
    "Stworzone klasyfikatory będą oceniane na osobnym zbiorze danych, który dostarczy prowadzący. Ocena będzie oparta o uśrednioną po wszystkich klasach miarę recall (ang. macro-averaged recall).\n",
    "\n",
    "Zadanie zrealizowano w języku Python z użyciem bibliotek Pandas i scikit-learn. Uzyskane estymacja miary recall dla klasyfikatorów mających być testowanych na zadanych danych testowych wyniosła odpowiednio: 0.41 i 0.44 dla danych oryginalnych i z podmienionymi etykietami."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Lista użytych bibliotek\"\"\"\n",
    "import pandas as pd\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.externals import joblib\n",
    "import re\n",
    "import cPickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"definicja klasy zawierającej wszystkie funkcjonalności pod postacią funkcji\"\"\"\n",
    "class MyClassifierEngine:\n",
    "    def __init__(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"funkcje ładujące z plików data frame'y wejściowe\"\"\"\n",
    "def loadFirstDF(self):\n",
    "    return pd.read_csv(\"../input/all_summary.txt\", sep=\";\", na_values=[\"nan\"])\n",
    "def loadResNames(self):\n",
    "    return pd.read_csv(\"../input/grouped_res_name.txt\", sep=\",\", na_values=[\"nan\"])\n",
    "def loadTestDataDF(self):\n",
    "    return pd.read_csv(\"../input/test_data.txt\", sep=\",\", na_values=[\"nan\"])\n",
    "MyClassifierEngine.loadFirstDF = loadFirstDF\n",
    "MyClassifierEngine.loadResNames = loadResNames\n",
    "MyClassifierEngine.loadTestDataDF = loadTestDataDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\" funkcja odfiltrowująca kolumny:\n",
    "  - z wartościami będącymi ciągami znaków, \n",
    "  - posiadającymi wyłącznie wartości Na, \n",
    "  - posiadające tylko jedną i tę samą wartość, co nie jest przydatne do trenowania, czy testowania klasyfikatora,\n",
    "  - posiadające wartości pasujące do wzorców wyrażeń regularnych: '^part_0[1-9].*' i '^part_1.*', \n",
    "         ponieważ są mocno skorelowane z pozostawionymi kolumnami\"\"\"\n",
    "def filterColumns(self, df):\n",
    "    columnsWithStringValues = [\"title\", \"chain_id\", \"res_id\"]\n",
    "    columnsWithOnlyNas = [\"local_BAa\", \"local_NPa\", \"local_Ra\", \"local_RGa\", \"local_SRGa\", \"local_CCSa\", \"local_CCPa\", \"local_ZOa\", \"local_ZDa\", \"local_ZD_minus_a\", \"local_ZD_plus_a\", \"weight_col\"]\n",
    "    columnsWithSameValue = [\"local_min\", \"fo_col\", \"fc_col\", \"grid_space\", \"solvent_radius\", \"solvent_opening_radius\", \"resolution_max_limit\", \"part_step_FoFc_std_min\", \"part_step_FoFc_std_max\", \"part_step_FoFc_std_step\"]\n",
    "    columnsToRemovePattern1 = r'^part_0[1-9].*'\n",
    "    columnsToRemovePattern2 = r'^part_1.*'\n",
    "    correctColumns = []\n",
    "    for e in df.columns:\n",
    "        if not( e in columnsWithStringValues or e in columnsWithOnlyNas or e in columnsWithSameValue or re.search(columnsToRemovePattern1, e) or re.search(columnsToRemovePattern2, e)):\n",
    "            correctColumns.append(e)\n",
    "    return df.loc[:, correctColumns]\n",
    "MyClassifierEngine.filterColumns = filterColumns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"funkcja odfiltrowująca kolumny dla danych testowych, w których nie ma 15 kolumn, które podnoszą jakość klasyfikacji. \n",
    "   Wykorzystuje funkcję filterColumns\"\"\"\n",
    "def filterColumnsForTestData(self, df):\n",
    "    df = self.filterColumns(df)\n",
    "    columnsLackingInTestData = [\"local_res_atom_count\", \"local_res_atom_non_h_count\", \"local_res_atom_non_h_occupancy_sum\", \"local_res_atom_non_h_electron_sum\", \"local_res_atom_non_h_electron_occupancy_sum\", \"local_res_atom_C_count\", \"local_res_atom_N_count\", \"local_res_atom_O_count\", \"local_res_atom_S_count\", \"dict_atom_non_h_count\", \"dict_atom_non_h_electron_sum\", \"dict_atom_C_count\", \"dict_atom_N_count\", \"dict_atom_O_count\", \"dict_atom_S_count\", \"local_volume\", \"local_electrons\", \"local_mean\", \"local_std\"]\n",
    "    correctColumns = []\n",
    "    for e in df.columns:\n",
    "        if not(e in columnsLackingInTestData):\n",
    "            correctColumns.append(e)\n",
    "    return df.loc[:, correctColumns]\n",
    "MyClassifierEngine.filterColumnsForTestData = filterColumnsForTestData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"Usunięcie wierszy posiadających wartość zmiennych res_name równą: \n",
    "   “DA”,“DC”,“DT”, “DU”, “DG”, “DI”,“UNK”, “UNX”, “UNL”, “PR”, “PD”, “Y1”, “EU”, “N”, “15P”, “UQ”, “PX4” lub “NAN”;\"\"\"\n",
    "def filterRowsByResName(self, df):\n",
    "    forbiddenResName = [\"DA\",\"DC\",\"DT\", \"DU\", \"DG\", \"DI\",\"UNK\", \"UNX\", \"UNL\", \"PR\", \"PD\", \"Y1\", \"EU\", \"N\", \"15P\", \"UQ\", \"PX4\", \"NAN\"]\n",
    "    return df[df[\"res_name\"].apply(lambda x: not (x in forbiddenResName))]\n",
    "MyClassifierEngine.filterRowsByResName = filterRowsByResName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"W zbiorze danych uczących powinny zostać tylko unikatowe pary (pdb_code, res_name)\"\"\"\n",
    "def filterRwosByDistinctPairs(self, df):\n",
    "    e = []\n",
    "    distinctSet = set([])\n",
    "    for i in df.index:\n",
    "        value = \"{}_{}\".format(df.loc[i,\"pdb_code\"],df.loc[i,\"res_name\"])\n",
    "        if(value in distinctSet):\n",
    "            e.append(False)\n",
    "        else :\n",
    "            distinctSet.add(value)\n",
    "            e.append(True)\n",
    "    return df[e]\n",
    "MyClassifierEngine.filterRwosByDistinctPairs = filterRwosByDistinctPairs    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Pozostawienie wszystkich klas, których liczność wynosi co najmniej 5 przykładów; \n",
    "   klasy o mniejszej liczności nie mają być brane pod uwagę\"\"\"\n",
    "def filterRowsByGroupSize(self, df, column=\"res_name\", value = 5):\n",
    "    f = df.groupby(column).size()\n",
    "    return df[df[column].apply(lambda x: (pd.isnull(x) or (f[x] >= value)))]\n",
    "MyClassifierEngine.filterRowsByGroupSize = filterRowsByGroupSize    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"Nauczenie klasyfikatora, estymacja miary recall, wykorzystanie kodu optymalizującego parametry metodą grid search\"\"\"\n",
    "def learnClfRandomForest(self, X, y, printBestParams = True, printClassificationReport = True):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.75, random_state=0)\n",
    "    tuned_parameters = [{\"max_depth\": [10,50,None],\n",
    "                 \"criterion\": [\"gini\", \"entropy\"],\n",
    "                 \"n_estimators\": [2,10,30]}]\n",
    "    scores = ['recall']\n",
    "\n",
    "    for score in scores:\n",
    "        clf = GridSearchCV(RandomForestClassifier(), tuned_parameters, cv=5, scoring='%s_weighted' % score)\n",
    "        clf.fit(X_train, y_train)\n",
    "        if(printBestParams):\n",
    "            print(clf.best_params_)\n",
    "\n",
    "    y_true, y_pred = y_test, clf.predict(X_test)\n",
    "    if(printClassificationReport):\n",
    "        print(classification_report(y_true, y_pred))\n",
    "    return clf\n",
    "MyClassifierEngine.learnClfRandomForest = learnClfRandomForest  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Zapisywanie wyniku klasyfikacji do pliku. Wykorzystywane do utworzenia pliku z klasami przypisanymi do danych testowych\n",
    "   zamieszczonych przez prowadzącego, w celu porównania przydzielonych klas z faktycznymi\"\"\"\n",
    "def saveTestClassification(self, fileName, data):\n",
    "    f = open('../{}.txt'.format(fileName),'w')\n",
    "    j=1\n",
    "    f.write('\"\",\"res_name\"\\n')\n",
    "    for i in data:\n",
    "        f.write('\"{}\",\"{}\"\\n'.format(j,i))\n",
    "        j += 1\n",
    "    f.close()\n",
    "MyClassifierEngine.saveTestClassification = saveTestClassification  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Serializacja i deserializacja klasyfikatorów. Do serializacji wykorzystywano bibliotekę joblib, wg wymagań projektowych.\n",
    "   Spostrzeżono jednak problemy z załadowaniem zserializowanego klasyfikatora typu RandomForest, zatem dodatkowo wykorzystano\n",
    "   serializację i deserializację przy pomocy modułu cPickle.\"\"\"\n",
    "def exportClf(self, clf, fileName):\n",
    "    joblib.dump(clf.best_estimator_, '{}.pkl'.format(fileName))\n",
    "    with open('{}.pickle'.format(fileName), 'wb') as f:\n",
    "        cPickle.dump(clf.best_estimator_, f)\n",
    "def importClf(self, fileName):\n",
    "    with open('{}.pickle'.format(fileName), 'rb') as f:\n",
    "        return cPickle.load(f)\n",
    "MyClassifierEngine.exportClf = exportClf \n",
    "MyClassifierEngine.importClf = importClf   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Metoda komponująca funkcję w jedną funkcjonalność - tworzenie klasyfikatora na podstawie danych podstawowych. Dane są ładowane, kolumny i wiersze są filtrowane.\n",
    "   Po uzyskaniu wymaganych 11005 wierszy usuwane zostają wiersze zawierające wartości nan. \n",
    "   Takie wartości nie mogą być użyte do nauki klasyfikatora a zastąpienie ich wartością arbitralną lub pewną statystyką kolumny(średnią)\n",
    "   mogłoby oszukać podczas trenowania klasyfikatora. Następnie ponownie usuwane są mało liczne grupy pod względem res_name.\n",
    "   Utworzony klasyfikator zostaje poddany serializacji\"\"\"\n",
    "def firstLearning(self):\n",
    "    print(\"\\n\\nfirstLearning\\n\")\n",
    "    df = self.loadFirstDF()\n",
    "    df = self.filterColumns(df)\n",
    "    df = self.filterRowsByResName(df)\n",
    "    df = self.filterRwosByDistinctPairs(df)\n",
    "    df = self.filterRowsByGroupSize(df)\n",
    "    del df[\"pdb_code\"]\n",
    "\n",
    "    df = df.dropna(how=\"any\")\n",
    "    df = self.filterRowsByGroupSize(df)\n",
    "\n",
    "    X = df.iloc[:,1:]\n",
    "    y = df.iloc[:,0]\n",
    "    clf = self.learnClfRandomForest(X,y)\n",
    "\n",
    "    self.exportClf(clf, 'randomForest1')\n",
    "    return clf\n",
    "MyClassifierEngine.firstLearning = firstLearning  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Metoda komponująca funkcje, aby utworzyć klasyfikator ustawiający do danego data frame'a etykiety wierszy z pliku danego przez prowadzącego przedmiot.\n",
    "   Od poprzedniej metody różni się sposobem uzyskania data frame'ów X oraz y wykorzystanych do nauczenia klasyfikatora.\n",
    "   Indeksy wierszy zostają zsynchronizowane, ze starego data frame'a zostaje usunięta kolumna res_name i dodana kolumna res_name_group\n",
    "   z data frame'a wczytanego z pliku.\"\"\"\n",
    "def secondLearning(self):\n",
    "        print(\"\\n\\nsecondLearning\\n\")\n",
    "        df = self.loadFirstDF()\n",
    "        df = self.filterColumns(df)\n",
    "        df = self.filterRowsByResName(df)\n",
    "        df = self.filterRwosByDistinctPairs(df)\n",
    "        df = self.filterRowsByGroupSize(df)\n",
    "        del df[\"pdb_code\"]\n",
    "\n",
    "        del df[\"res_name\"]\n",
    "        dfy = self.loadResNames()\n",
    "        df.index = dfy.index\n",
    "        df = pd.concat([dfy.loc[:,\"res_name_group\"], df], axis=1)\n",
    "        df = df.dropna(how=\"any\")\n",
    "\n",
    "        X = df.iloc[:,1:]\n",
    "        y = df.iloc[:,0]\n",
    "        clf = self.learnClfRandomForest(X,y)\n",
    "\n",
    "        self.exportClf(clf, 'randomForest2')\n",
    "        return clf\n",
    "MyClassifierEngine.secondLearning = secondLearning  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Metoda tworząca klasyfikator wykorzystany do sklasyfikowania danych z pliku testowego, na etykietach oryginalnych. \n",
    "   Od poprzedniego klasyfikatora różni się wykorzystaniem innej metody do filtrowania kolumn data frame'a.\n",
    "   filterColumnsForTestData zamiast filterColumns, ponieważ odfiltrowuje też ważne kolumny, których jednak nie ma w zbiorze danych testowych\"\"\"\n",
    "def firstTestLearning(self):\n",
    "    print(\"\\n\\nfirstTestLearning\\n\")\n",
    "    df = self.loadFirstDF()\n",
    "    df = self.filterColumnsForTestData(df)\n",
    "    df = self.filterRowsByResName(df)\n",
    "    df = self.filterRwosByDistinctPairs(df)\n",
    "    df = self.filterRowsByGroupSize(df)\n",
    "    del df[\"pdb_code\"]\n",
    "\n",
    "    df = df.dropna(how=\"any\")\n",
    "    df = self.filterRowsByGroupSize(df)\n",
    "\n",
    "    X = df.iloc[:,1:]\n",
    "    y = df.iloc[:,0]\n",
    "    clf = self.learnClfRandomForest(X,y)\n",
    "\n",
    "    self.exportClf(clf, 'randomForestFirstTest')\n",
    "    return clf\n",
    "MyClassifierEngine.firstTestLearning = firstTestLearning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Metoda tworząca klasyfikator wykorzystany do sklasyfikowania danych z pliku testowego na etykietach pogrupowanych.\n",
    "   Jak poprzednia metoda odfiltrowuje  ważne kolumny, których nie ma w zbiorze danych testowych\"\"\"\n",
    "def secondTestLearning(self):\n",
    "    print(\"\\n\\nsecondTestLearning\\n\")\n",
    "    df = self.loadFirstDF()\n",
    "    df = self.filterColumnsForTestData(df)\n",
    "    df = self.filterRowsByResName(df)\n",
    "    df = self.filterRwosByDistinctPairs(df)\n",
    "    df = self.filterRowsByGroupSize(df)\n",
    "    del df[\"pdb_code\"]\n",
    "\n",
    "    del df[\"res_name\"]\n",
    "    dfy = self.loadResNames()\n",
    "    df.index = dfy.index\n",
    "    df = pd.concat([dfy.loc[:,\"res_name_group\"], df], axis=1)\n",
    "    df = df.dropna(how=\"any\")\n",
    "\n",
    "    X = df.iloc[:,1:]\n",
    "    y = df.iloc[:,0]\n",
    "    clf = self.learnClfRandomForest(X,y)\n",
    "\n",
    "    self.exportClf(clf, 'randomForesSecondTest')\n",
    "    return clf\n",
    "MyClassifierEngine.secondTestLearning = secondTestLearning  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Metoda przeprowadzająca klasyfikację danych testowych. Wartości nan z pliku wejściowego zostają zamienione na 0. \n",
    "   Nie można pominąć wierszy zawierających takie wartości, gdyż dla każdego wiersza musi zostać przypisana klasa.\"\"\"\n",
    "def testFirstClassification(self):\n",
    "    print(\"\\n\\ntestFirstClassification\\n\")\n",
    "    df = self.loadTestDataDF()\n",
    "    df = df.iloc[:,1:]\n",
    "    df = self.filterColumnsForTestData(df)\n",
    "    df = df.fillna(value=0)\n",
    "\n",
    "    clf = self.importClf('randomForestFirstTest')\n",
    "    print(\"**********************\")\n",
    "    result = clf.predict(df)\n",
    "    self.saveTestClassification(\"outputFirst\", result)\n",
    "\n",
    "def testSecondClassification(self):\n",
    "    print(\"\\n\\ntestClassification\\n\")\n",
    "    df = self.loadTestDataDF()\n",
    "    df = df.iloc[:,1:]\n",
    "    df = self.filterColumnsForTestData(df)\n",
    "    df = df.fillna(value=0)\n",
    "\n",
    "    clf = self.importClf('randomForesSecondTest')\n",
    "    print(\"**********************\")\n",
    "    result = clf.predict(df)\n",
    "    self.saveTestClassification(\"outputSecond\", result)\n",
    "    \n",
    "MyClassifierEngine.testFirstClassification = testFirstClassification \n",
    "MyClassifierEngine.testSecondClassification = testSecondClassification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"Utworzenie klasyfikatora na podstawie oryginalnego zbioru etykiet (res_name), z kolumnami nie występującymi w zbiorze testowym\"\"\"\n",
    "mce1 = MyClassifierEngine()\n",
    "mce1.firstLearning()\n",
    "#mean recall: 0.87, dla danych testowych wydzielonych z oryginalnego zbioru danych\n",
    "\"\"\"Utworzenie klasyfikatora na potstawie pogrupowanych etykiet, z kolumnami nie występującymi w zbiorze testowym\"\"\"\n",
    "mce2 = MyClassifierEngine()\n",
    "mce2.secondLearning()\n",
    "#mean recall: 0.93, dla danych testowych wydzielonych z oryginalnego zbioru danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"Utworzenie klasyfikatora na podstawie oryginalnego zbioru etykiet, przeznaczony do testowania na zadanym zbiorze testowym\"\"\"\n",
    "mce3 = MyClassifierEngine()\n",
    "mce3.firstTestLearning()\n",
    "#mean recall: 0.41, dla dodatkowych danych testowych "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jerzy\\Anaconda2\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 175, in do_execute\n    shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"C:\\Users\\Jerzy\\Anaconda2\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2832, in run_cell\n    cell = self.input_transformer_manager.transform_cell(raw_cell)\n",
      "  File \"C:\\Users\\Jerzy\\Anaconda2\\lib\\site-packages\\IPython\\core\\inputsplitter.py\", line 595, in transform_cell\n    self.reset()\n",
      "  File \"C:\\Users\\Jerzy\\Anaconda2\\lib\\site-packages\\IPython\\core\\inputsplitter.py\", line 534, in reset\n    try:\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Utworzenie klasyfikatora na podstawie oryginalnego zbioru etykiet, przeznaczony do testowania na zadanym zbiorze testowym\"\"\"\n",
    "mce4 = MyClassifierEngine()\n",
    "mce4.secondTestLearning()\n",
    "#mean recall: 0.44, dla dodatkowych danych testowych "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Uruchomienie testów dla ostatnich dwóch klasyfikatorów na dostarczonych danych testowych\"\"\"\n",
    "mceTestFirst = MyClassifierEngine()\n",
    "mceTestFirst.testFirstClassification()\n",
    "\n",
    "mceTestSecond = MyClassifierEngine()\n",
    "mceTestSecond.testSecondClassification()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
